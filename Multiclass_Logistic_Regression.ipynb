{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 Multiclass Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"mnist_train.csv\")\n",
    "df=df.sort_values(['label'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=(df[df['label']<5]).drop('label',axis=1)\n",
    "x_train=(x_train/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df[df['label']<5][['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot coding for traing lables\n",
    "y_label=np.zeros((len(y),len(y.label.unique())))\n",
    "y_=np.array(y)\n",
    "for i in range(len(y.label.unique())):\n",
    "    for j in range(len(y)):\n",
    "        if y_[j]==y.label.unique()[i]:\n",
    "            y_label[j,i]=1\n",
    "        else:\n",
    "            y_label[j,i]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    \n",
    "    def __init__(self,learning_rate):\n",
    "        self.learning_rate=learning_rate\n",
    "    \n",
    "    \n",
    "    def softmax(self,z):\n",
    "        return (np.exp(z)/np.sum(np.exp(z)))\n",
    "    \n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        n_samples,n_features=x.shape\n",
    "        self.bias=np.zeros((1,5))\n",
    "        self.weights=np.zeros((n_features,5))\n",
    "        \n",
    "        for i in range(100):\n",
    "            self.model=self.bias+np.dot(x,self.weights)\n",
    "            y_hat=self.softmax(self.model)\n",
    "            #print(y_hat.shape)\n",
    "            \n",
    "            #gradient descent\n",
    "            db=np.array((1/len(x))*np.sum(y_hat-y))\n",
    "            dw=(1/len(x))*(np.dot(x.T,(y_hat-y)))\n",
    "            \n",
    "            #update weights\n",
    "            self.weights-=self.learning_rate*dw\n",
    "            self.bias-=self.learning_rate*db\n",
    "            \n",
    "            #stopping criteria\n",
    "            #if self.bias[0]<0.0001 and self.weights[0]<0.0001 and self.weights[1]<0.0001:\n",
    "                #print('Number of iternations required to converge: ',i)\n",
    "                #break\n",
    "        \n",
    "    def train(self,x):\n",
    "        self.model=self.bias+np.dot(x,self.weights)\n",
    "    \n",
    "    def predict(self,x):\n",
    "        self.y_probability=self.softmax(self.model)\n",
    "        #y_predicted=[1 if y_probability>=0.5 else 0 for y_probability in self.y_probability]\n",
    "        #self.y_predicted=np.asarray(y_predicted)\n",
    "        self.y_predicted=np.array(self.y_probability.argmax(axis=1).reshape((len(x),1)))\n",
    "        #return self.y_predicted\n",
    "    \n",
    "    def accuracy(self,x,y):\n",
    "        count=0\n",
    "        for i in range(len(x)):\n",
    "            if self.y_predicted[i]==np.array(y)[i]:\n",
    "                count+=1\n",
    "        return (count/len(x))*100\n",
    "    \n",
    "    def roc_curve(self,x,y):\n",
    "        y=np.array(y)\n",
    "        tp=0\n",
    "        tn=0\n",
    "        fp=0\n",
    "        fn=0\n",
    "        for i in range(len(x)):\n",
    "            if self.y_predicted[i]==1 and y[i]==1:\n",
    "                tp+=1\n",
    "            else:\n",
    "             if self.y_predicted[i]==0 and y[i]==0:\n",
    "                 tn+=1   \n",
    "            if self.y_predicted[i]==1 and y[i]==0:\n",
    "                fp+=1\n",
    "            else:\n",
    "             if self.y_predicted[i]==0 and y[i]==1:\n",
    "                fn+=1\n",
    "        true_positive_rate=tp/(tp+fn)\n",
    "        false_positive_rate=fp/(fp+tn)\n",
    "        print(tp,fn,fp,tn)\n",
    "        return true_positive_rate,false_positive_rate\n",
    "    \n",
    "    def loss(self,x,y):\n",
    "        loss= -(1/len(x)*np.sum(y*np.log(self.y_probability)+(1-y)*np.log(1-self.y_probability)))\n",
    "        print('Loss: ',loss)\n",
    "        \n",
    "    def probability(self):\n",
    "        return self.y_probability\n",
    "    \n",
    "    \n",
    "    def predict_class(self):\n",
    "        return self.y_predicted\n",
    "    \n",
    "    def roc(self,x,y):\n",
    "        y=np.array(y)\n",
    "        for j in range(5):\n",
    "             for i in range(len(x)):\n",
    "                self.model=self.bias+np.dot(x.iloc[i,:],self.weights)\n",
    "                prob=self.softmax(self.model)\n",
    "                if np.logical_and(prob[:,0]>=0.5,y[j]==1):\n",
    "                    count+=1\n",
    "                if np.logical_and(prob[:,0]<=0.5,y[j]==0):\n",
    "                    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.32474833311544"
      ]
     },
     "execution_count": 1007,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=LogisticRegression(0.001)\n",
    "l.fit(x_train,y_label)\n",
    "l.train(x_train)\n",
    "l.predict(x_train)\n",
    "l.accuracy(x_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv(\"mnist_test.csv\")\n",
    "df_test=df_test.sort_values(['label'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=(df_test[df_test['label']<5]).drop('label',axis=1)\n",
    "x_test=(x_test/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=df_test[df_test['label']<5][['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot coding for testing \n",
    "y_label_test=np.zeros((len(y_test),len(y_test.label.unique())))\n",
    "y_=np.array(y_test)\n",
    "for i in range(len(y_test.label.unique())):\n",
    "    for j in range(len(y_test)):\n",
    "        if y_[j]==y_test.label.unique()[i]:\n",
    "            y_label_test[j,i]=1\n",
    "        else:\n",
    "            y_label_test[j,i]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on Testing Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.46409807355516"
      ]
     },
     "execution_count": 997,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.train(x_test)\n",
    "l.predict(x_test)\n",
    "l.accuracy(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981 0 0 972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0)"
      ]
     },
     "execution_count": 998,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.roc_curve(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, Recall and F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.99      0.86       980\n",
      "           1       0.99      0.86      0.92      1135\n",
      "           2       0.83      0.76      0.79      1032\n",
      "           3       0.79      0.90      0.84      1010\n",
      "           4       0.98      0.76      0.86       982\n",
      "\n",
      "    accuracy                           0.85      5139\n",
      "   macro avg       0.87      0.86      0.85      5139\n",
      "weighted avg       0.87      0.85      0.86      5139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_hat=l.predict_class()\n",
    "print(classification_report(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
